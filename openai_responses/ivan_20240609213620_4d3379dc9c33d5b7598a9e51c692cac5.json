```json
{
    "summary": "<h2>Profile and Content Updates</h2>\
<h3>Main Content Changes</h3>\
<p>The body content now includes detailed personal and professional information about Ivan Vendrov. Specifically, the content was expanded to include:</p>\
<p>Hi! I&rsquo;m Ivan. Welcome to my little corner of the internet!</p>\
<p>I&rsquo;m currently leading the collective intelligence team at Midjourney - building AI tools to help people better understand each other and coordinate with each other; coordination is the scarcest resource and the one we&rsquo;ll need most in the coming decades. If you&rsquo;re interested in this, please reach out!</p>\
<p>Previously I was a member of technical staff at <a href=\"https://www.anthropic.com\">Anthropic</a>, working on safe deployment of advanced AI systems. Before that, I was co-founder and CTO at <a href=\"https://about.omnilabs.ai\">Omni</a>, an ML company seeking to augment human intelligence by bringing all knowledge to thought. Before Omni I worked on building <a href=\"https://scholar.google.com/citations?view_op=view_citation&hl=en&user=k8TR3FQAAAAJ&citation_for_view=k8TR3FQAAAAJ:d1gkVwhDpl0C\">conversational recommender systems</a> at Google Research, and before that on <a href=\"https://arxiv.org/abs/1511.06361\">embedding visual-semantic hierarchies in latent spaces</a> at the University of Toronto.</p>\
<p>I am deeply concerned about <a href=\"https://en.wikipedia.org/wiki/The_Precipice:_Existential_Risk_and_the_Future_of_Humanity\">existential risk</a> and in particular <a href=\"https://en.wikipedia.org/wiki/Human_Compatible\">risks from misaligned AI</a>. I believe the best way to make progress on AI alignment is to work on aligning the most influential AI systems deployed in the world today: recommender systems. I outlined the case for doing so in <a href=\"https://forum.effectivealtruism.org/posts/xzjQvqDYahigHcwgQ/aligning-recommender-systems-as-cause-area\">Aligning Recommender Systems as Cause Area</a>, maintain a list of <a href=\"https://docs.google.com/document/d/16tIpuu8WexxlM-3XpEub05BOTCFNiyvIVzZNXX0uDWw/edit\">shovel-ready projects in recommender alignment</a>.</p>\
<p>I hope to help preserve and make accessible all knowledge, all narrative, all experience. I love <a href=\"https://www.wikipedia.org/\">Wikipedia</a>, <a href=\"http://libgen.is/\">Library Genesis</a>, <a href=\"https://sci-hub.se/\">Sci-Hub</a>, <a href=\"https://ipfs.io/\">IPFS</a>; Alexandra Elbakyan and Aaron Swartz are among my heroes.</p>\
<p>You can find out more about my work and ideas on my blog <a href=\"https://nothinghuman.substack.com\">Nothing Human</a>, my <a href=\"https://scholar.google.com/citations?hl=en&user=k8TR3FQAAAAJ\">Google Scholar</a>, <a href=\"https://www.lesswrong.com/users/ivan-vendrov\">LessWrong</a>, the <a href=\"https://forum.effectivealtruism.org/users/ivanvendrov\">EA Forum</a>, and in the <a href=\"fragments\">Fragments</a> section of this site.</p>\
<h3>Image Elements</h3>\
<p>The head section of the document now includes links to social media icons referencing Twitter, Github, and LinkedIn for better connectivity. Relevant images are:</p>\
<p>Twitter: <a href=\"https://twitter.com/IvanVendrov\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/1/16/Twitter_bird_logo_2012.svg\" alt=\"Twitter\"></a></p>\
<p>Github: <a href=\"https://github.com/ivendrov\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg\" alt=\"Github\"></a></p>\
<p>LinkedIn: <a href=\"https://www.linkedin.com/in/ivanvendrov/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/3/33/LinkedIn_logo_initials.png\" alt=\"LinkedIn\"></a></p>\
<h3>Links and References</h3>\
<p>The footer section has updated to include new social media links:</p>\
<ul>\
<li><a href=\"https://twitter.com/IvanVendrov\" target=_blank>Twitter</a></li>\
<li><a href=\"https://github.com/ivendrov\" target=_blank>Github</a></li>\
<li><a href=\"https://www.linkedin.com/in/ivanvendrov/\" target=_blank>LinkedIn</a></li>\
</ul>",
    "score": 7
}
```